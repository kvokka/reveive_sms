#!/usr/bin/env ruby

require 'uri'
require 'async'
require 'async/barrier'
require 'async/semaphore'
require 'async/http/internet'
require 'nokogiri'
require 'progressbar'
require 'hirb'

module ReceiveSms
  class Crawler
    class << self
      attr_accessor :base_uri
      attr_accessor :concurrency
      attr_accessor :timeout
    end
    self.base_uri = URI 'https://receive-sms.cc'
    self.concurrency = 20
    self.timeout = 60

    def countries_paths
      @countries_paths ||= fetch("/Countries/").
        first.
        html.
        css('.number-boxes-item-button').
        map { |a| a.attributes&.fetch('href', nil)&.value }
    rescue
      puts '==> Failed to fetch countries list'
      raise
    end

    def numbers
      return @numbers if @numbers

      progressbar = ProgressBar.create(total: countries_paths.size, title: ' Fetching countries data')
      @numbers = fetch(countries_paths).each_with_object([]) do |first_page_per_country, acc|
        last_page_number = first_page_per_country.
          html.
          css('ul.pagination li').
          last&.
          children&.
          last&.
          attributes&.
          fetch('href', nil)&.
          value&.
          split('/')&.
          last&.
          to_i

        pages = [first_page_per_country]
        if last_page_number.to_i > 1
          pages += fetch((2..last_page_number).map{ |pn| "#{first_page_per_country.path}/Page/#{pn}" })
        end
        pages.each do |page|

          page.html.css('.number-boxes-item-button').each do |button|
            path = button.attributes&.fetch('href', nil)&.value
            full_path = self.class.base_uri + path
            number = path.split('/').last

            acc << OpenStruct.new(path: path, full_path: full_path, number: number)
          end
        end
        progressbar.increment
      end
    end

    # No multithreading in here and i'm ok with it.
    # Improve when this became too slow
    def numbers_with_popularity
      return @numbers_with_popularity if @numbers_with_popularity

      progressbar = ProgressBar.create(total: numbers.size, title: ' Fetching numbers data')
      fetch(numbers.map(&:path)).each_with_index do |page, i|
        number = numbers.detect { |n| n.path == page.path }
        next (puts "===> Page for path #{path} not found") unless number

        number.received = page.
          html.
          search('div.row').
          map(&:content).
          map {|s| s.match(/Received (\d+) text messages\z/)&.captures&.first }.
          compact.
          first.
          to_i
        number.last_activity = page.
          html.
          search('div.row.border-bottom.border-temps.table-hover').
          first(3).
          map{ |d| d.children[3].content }.
          uniq.
          map{ |s| s.sub(' ago', '') }.
          join(', ').
          concat(' ago')
        progressbar.increment
      rescue
        puts "===> Something went wrong with number #{number.number}. Skipping"
        next
      end
      @numbers_with_popularity = numbers
    end

    private

    def fetch(paths)
      [].tap do |result|
        Async do |task|
          internet = Async::HTTP::Internet.new
          barrier = Async::Barrier.new
          semaphore = Async::Semaphore.new(self.class.concurrency, parent: barrier)

          # Spawn an asynchronous task for each topic:
            task.with_timeout(self.class.timeout) do
              Array(paths).each do |path|
                semaphore.async do
                  headers = [['User-Agent', "Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:#{rand(47..80)}.0) Gecko/20100101 Firefox/#{rand(47..80)}.0"]]
                  response = internet.get((self.class.base_uri + path).to_s, headers)
                  result << OpenStruct.new(path: path, html: Nokogiri::HTML(response.read))
                end
              end

            # Ensure we wait for all requests to complete before continuing:
            barrier.wait
          end
        rescue Async::TimeoutError
          puts "===> The request timed out for #{path}"
        ensure
          internet&.close
        end
      end
    end
  end
end

started_at = Time.now
numbers= ReceiveSms::Crawler.new.numbers_with_popularity
puts "It took #{(Time.now - started_at).to_i} seconds"

extend Hirb::Console
table numbers.
  select(&:received).
  sort_by(&:received).
  reject { |n| n.last_activity =~ /day/ || n.last_activity =~ /week/ },
  fields: [:full_path, :received, :last_activity],
  resize: false,
  max_fields: { :last_activity=> 40 },
  headers: { last_activity: 'Last activity', full_path: 'URL', received: 'Received' }
